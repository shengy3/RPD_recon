{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(ary):\n",
    "    n_event = ary[:,1]\n",
    "    inic_q_avg = ary[:, 2]\n",
    "    hit_signal = ary[:, 3]\n",
    "\n",
    "    out = []\n",
    "    for item in [n_event, hit_signal, inic_q_avg]:\n",
    "        out.append(convert_np_array(item))\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(ary):\n",
    "    init_hit = ary[0]\n",
    "    signal = process_signal(ary[1])\n",
    "    #signal = ary[1]\n",
    "    \n",
    "    inic_q_avg = ary[2]\n",
    "    return init_hit, signal, inic_q_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_signal(ary, normalization = False, flatten = False, pad = 1):\n",
    "    if normalization:\n",
    "            ary = np.array([i.reshape(4,4,1)/np.sum(i) for i in ary])\n",
    "    else:\n",
    "        ary = np.array([i.reshape(4,4,1) for i in ary])\n",
    "    if flatten:\n",
    "            ary = np.array([i.reshape(16) for i in ary])\n",
    "    if pad:\n",
    "        ary = np.pad(ary[:, :, :, :], ((0, 0), (pad, pad), (pad, pad), (0,0)), 'constant')\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_np_array(ary):\n",
    "    return np.array([i for i in ary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New photon\n",
    "def get_charge(folder = \"./Data/Run4_MC_photon_signal/\", side = 'A'):\n",
    "    output = []\n",
    "    start = time.time()\n",
    "    for i in range(1000, 3000, 1000):\n",
    "        if i % 5000 == 0:\n",
    "            print(\"event\", i, \"time\", time.time() - start)\n",
    "            start = time.time()\n",
    "        try:\n",
    "            output.append(pd.read_pickle(folder + f\"{side}_RPD_photon{i}.pickle\"))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Missing file: {i}\")\n",
    "            continue\n",
    "    return pd.concat(output, ignore_index = True).set_index('Event number').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit_vector(arr):\n",
    "    output = []\n",
    "    norm =  np.linalg.norm(arr, axis = 1)\n",
    "    for i in range(arr.shape[0]):\n",
    "        output.append([arr[i][0] / norm[i], arr[i][1] / norm[i]])\n",
    "    return np.array(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/home/shengy3/ML_RPD/Data/Toy_fermi_qq_fiber_021022\"\n",
    "A_charge = get_charge(side = 'A',folder =  f\"{path}/pickle/\").drop_duplicates()\n",
    "B_charge = get_charge(side = 'B',folder =  f\"{path}/pickle/\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_charge.to_pickle(f\"{path}/Acharge.pickle\")\n",
    "B_charge.to_pickle(f\"{path}/Bcharge.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_list = []\n",
    "for i in (A_charge.index):\n",
    "    if i not in B_charge.index:\n",
    "        print(i)\n",
    "        del_list.append(i)\n",
    "        \n",
    "A_charge = A_charge.drop(del_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.4\n",
    "trainA, validA, trainB, validB = train_test_split(A_charge, B_charge, test_size=test_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validA.to_pickle(\"./Data/ToyV1_Fermi_2.7TeV_Merge_Charge_122420/validA.pickle\")\n",
    "#validB.to_pickle(\"./Data/ToyV1_Fermi_2.7TeV_Merge_Charge_122420/validB.pickle\")\n",
    "\n",
    "validA.to_pickle(f\"{path}/validA_dict.pickle\")\n",
    "validB.to_pickle(f\"{path}/validB_dict.pickle\")\n",
    "\n",
    "\n",
    "\n",
    "#np.save(\"./Data/ToyV1_Fermi_2.7TeV_Merge_Charge_122420/validA.npy\", validA)\n",
    "#np.save(\"./Data/ToyV1_Fermi_2.7TeV_Merge_Charge_122420/validB.npy\", validB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = trainA.append(trainB).to_numpy()\n",
    "valid = validA.append(validB).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_signal = train[:,8:]\n",
    "valid_signal = valid[:,8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_inic_q_avg = train[:, 2:4]\n",
    "v_inic_q_avg = valid[:, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_unit_vector = get_unit_vector(t_inic_q_avg)\n",
    "v_unit_vector = get_unit_vector(v_inic_q_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_signal = process_signal(train_signal, pad = 1, normalization = False)\n",
    "v_signal = process_signal(valid_signal, pad = 1, normalization = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.rcParams.update({\"savefig.bbox\": 'tight'})\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow.keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_nll(ytrue, ypreds):\n",
    "    \"\"\"Keras implmementation of multivariate Gaussian negative loglikelihood loss function. \n",
    "    This implementation implies diagonal covariance matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ytrue: tf.tensor of shape [n_samples, n_dims]\n",
    "        ground truth values\n",
    "    ypreds: tf.tensor of shape [n_samples, n_dims*2]\n",
    "        predicted mu and logsigma values (e.g. by your neural network)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    neg_log_likelihood: float\n",
    "        negative loglikelihood averaged over samples\n",
    "        \n",
    "    This loss can then be used as a target loss for any keras model, e.g.:\n",
    "        model.compile(loss=gaussian_nll, optimizer='Adam') \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_dims = int(int(ypreds.shape[1])/2)\n",
    "    mu = ypreds[:, 0:n_dims]\n",
    "    logsigma = ypreds[:, n_dims:]\n",
    "    \n",
    "    mse = -0.5*K.sum(K.square((ytrue-mu)/K.exp(logsigma)),axis=1)\n",
    "    sigma_trace = -K.sum(logsigma, axis=1)\n",
    "    log2pi = -0.5*n_dims*np.log(2*np.pi)\n",
    "    \n",
    "    log_likelihood = mse+sigma_trace+log2pi\n",
    "\n",
    "    return K.mean(-log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two sets of inputs\n",
    "# n_neutron = Input(shape=(1,), name = 'interact_neutron') # (40, ta_n)\n",
    "# # the first branch operates on the first input\n",
    "# x = Dense(4, activation=\"relu\")(n_neutron)\n",
    "# x = Dense(4, activation=\"relu\")(x)\n",
    "# x = Model(inputs=n_neutron, outputs=x)\n",
    "\n",
    "\n",
    "# the second branch opreates on the second input\n",
    "bias = Input(shape=(6,6,1), name = 'biased_RPD')\n",
    "y = Conv2D(filters = 64, kernel_size = (2,2),\\\n",
    "           padding = 'Same', activation ='relu')(bias)\n",
    "y = Conv2D(filters = 64, kernel_size = (2,2),\\\n",
    "           padding = 'Same', activation ='relu')(y)\n",
    "y = Flatten()(y)\n",
    "\n",
    "y = Dense(32, activation = \"relu\")(y)\n",
    "y = Dense(16, activation = \"relu\")(y)\n",
    "y = Dense(8, activation = \"relu\")(y)\n",
    "    \n",
    "y = Model(inputs=bias, outputs=y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q_avg = Dense(2, activation=\"linear\", name = 'Q_avg')(y.output)\n",
    "\n",
    "model = Model(inputs=[y.input], outputs=[Q_avg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics = ['mae', 'mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 1602 samples\n",
      "Epoch 1/75\n",
      "2400/2400 [==============================] - 1s 389us/sample - loss: 1731.0371 - mae: 33.3462 - mse: 1731.0371 - val_loss: 7101.9858 - val_mae: 75.1197 - val_mse: 7101.9858\n",
      "Epoch 2/75\n",
      "2400/2400 [==============================] - 0s 160us/sample - loss: 6910.1118 - mae: 74.0911 - mse: 6910.1118 - val_loss: 1587.5669 - val_mae: 36.1095 - val_mse: 1587.5669\n",
      "Epoch 3/75\n",
      "2400/2400 [==============================] - 0s 160us/sample - loss: 1541.3818 - mae: 35.6016 - mse: 1541.3818 - val_loss: 1171.7874 - val_mae: 31.6490 - val_mse: 1171.7874\n",
      "Epoch 4/75\n",
      "2400/2400 [==============================] - 0s 162us/sample - loss: 1143.2883 - mae: 31.2268 - mse: 1143.2883 - val_loss: 386.7155 - val_mae: 15.5474 - val_mse: 386.7155\n",
      "Epoch 5/75\n",
      "2400/2400 [==============================] - 0s 161us/sample - loss: 375.2444 - mae: 15.3089 - mse: 375.2444 - val_loss: 689.9193 - val_mae: 24.3428 - val_mse: 689.9193\n",
      "Epoch 6/75\n",
      "2400/2400 [==============================] - 0s 159us/sample - loss: 671.2239 - mae: 23.9405 - mse: 671.2239 - val_loss: 295.7738 - val_mae: 14.6526 - val_mse: 295.7738\n",
      "Epoch 7/75\n",
      "2400/2400 [==============================] - 0s 158us/sample - loss: 287.4346 - mae: 14.3667 - mse: 287.4346 - val_loss: 429.4016 - val_mae: 17.9353 - val_mse: 429.4016\n",
      "Epoch 8/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 419.2591 - mae: 17.7396 - mse: 419.2591 - val_loss: 262.0841 - val_mae: 14.6139 - val_mse: 262.0841\n",
      "Epoch 9/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 255.9289 - mae: 14.4304 - mse: 255.9289 - val_loss: 114.9671 - val_mae: 9.7412 - val_mse: 114.9671\n",
      "Epoch 10/75\n",
      "2400/2400 [==============================] - 0s 159us/sample - loss: 112.1711 - mae: 9.5870 - mse: 112.1711 - val_loss: 68.4137 - val_mae: 7.4532 - val_mse: 68.4137\n",
      "Epoch 11/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 66.7880 - mae: 7.3371 - mse: 66.7880 - val_loss: 42.5793 - val_mae: 5.7205 - val_mse: 42.5793\n",
      "Epoch 12/75\n",
      "2400/2400 [==============================] - 0s 154us/sample - loss: 41.3537 - mae: 5.5988 - mse: 41.3537 - val_loss: 26.7665 - val_mae: 4.3043 - val_mse: 26.7665\n",
      "Epoch 13/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 25.7445 - mae: 4.1950 - mse: 25.7445 - val_loss: 16.1759 - val_mae: 3.1248 - val_mse: 16.1759\n",
      "Epoch 14/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 15.3665 - mae: 3.0337 - mse: 15.3665 - val_loss: 9.1043 - val_mae: 2.2548 - val_mse: 9.1043\n",
      "Epoch 15/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 8.7243 - mae: 2.1817 - mse: 8.7243 - val_loss: 8.5684 - val_mae: 2.2663 - val_mse: 8.5684\n",
      "Epoch 16/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 8.4701 - mae: 2.2351 - mse: 8.4701 - val_loss: 12.0507 - val_mae: 2.6895 - val_mse: 12.0507\n",
      "Epoch 17/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 12.1630 - mae: 2.7119 - mse: 12.1630 - val_loss: 16.3600 - val_mae: 3.1600 - val_mse: 16.3600\n",
      "Epoch 18/75\n",
      "2400/2400 [==============================] - 0s 154us/sample - loss: 16.4650 - mae: 3.1766 - mse: 16.4650 - val_loss: 19.9565 - val_mae: 3.5302 - val_mse: 19.9565\n",
      "Epoch 19/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 20.0792 - mae: 3.5437 - mse: 20.0792 - val_loss: 21.3149 - val_mae: 3.6699 - val_mse: 21.3149\n",
      "Epoch 20/75\n",
      "2400/2400 [==============================] - 0s 153us/sample - loss: 21.4432 - mae: 3.6813 - mse: 21.4432 - val_loss: 19.9777 - val_mae: 3.5443 - val_mse: 19.9777\n",
      "Epoch 21/75\n",
      "2400/2400 [==============================] - 0s 154us/sample - loss: 20.0358 - mae: 3.5465 - mse: 20.0358 - val_loss: 17.2856 - val_mae: 3.2894 - val_mse: 17.2856\n",
      "Epoch 22/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 17.2300 - mae: 3.2622 - mse: 17.2300 - val_loss: 16.2106 - val_mae: 3.1601 - val_mse: 16.2106\n",
      "Epoch 23/75\n",
      "2400/2400 [==============================] - 0s 154us/sample - loss: 15.9872 - mae: 3.1358 - mse: 15.9872 - val_loss: 17.3479 - val_mae: 3.2325 - val_mse: 17.3479\n",
      "Epoch 24/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 17.2365 - mae: 3.2506 - mse: 17.2365 - val_loss: 17.7311 - val_mae: 3.2604 - val_mse: 17.7311\n",
      "Epoch 25/75\n",
      "2400/2400 [==============================] - 0s 154us/sample - loss: 17.6497 - mae: 3.2890 - mse: 17.6497 - val_loss: 15.1644 - val_mae: 3.0286 - val_mse: 15.1644\n",
      "Epoch 26/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 15.0755 - mae: 3.0529 - mse: 15.0755 - val_loss: 11.5901 - val_mae: 2.6679 - val_mse: 11.5901\n",
      "Epoch 27/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 11.4864 - mae: 2.6640 - mse: 11.4864 - val_loss: 9.6809 - val_mae: 2.4172 - val_mse: 9.6809\n",
      "Epoch 28/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 9.5728 - mae: 2.3844 - mse: 9.5728 - val_loss: 9.8705 - val_mae: 2.4028 - val_mse: 9.8705\n",
      "Epoch 29/75\n",
      "2400/2400 [==============================] - 0s 158us/sample - loss: 9.7783 - mae: 2.3718 - mse: 9.7783 - val_loss: 9.9674 - val_mae: 2.4195 - val_mse: 9.9674\n",
      "Epoch 30/75\n",
      "2400/2400 [==============================] - 0s 160us/sample - loss: 9.8838 - mae: 2.3994 - mse: 9.8838 - val_loss: 8.0942 - val_mae: 2.1861 - val_mse: 8.0942\n",
      "Epoch 31/75\n",
      "2400/2400 [==============================] - 0s 161us/sample - loss: 8.1191 - mae: 2.1750 - mse: 8.1191 - val_loss: 5.7620 - val_mae: 1.8466 - val_mse: 5.7620\n",
      "Epoch 32/75\n",
      "2400/2400 [==============================] - 0s 159us/sample - loss: 5.8585 - mae: 1.8498 - mse: 5.8585 - val_loss: 5.1566 - val_mae: 1.7392 - val_mse: 5.1566\n",
      "Epoch 33/75\n",
      "2400/2400 [==============================] - 0s 159us/sample - loss: 5.2387 - mae: 1.7568 - mse: 5.2387 - val_loss: 5.7767 - val_mae: 1.8449 - val_mse: 5.7767\n",
      "Epoch 34/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 5.7647 - mae: 1.8502 - mse: 5.7647 - val_loss: 5.9461 - val_mae: 1.8807 - val_mse: 5.9461\n",
      "Epoch 35/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 5.8836 - mae: 1.8830 - mse: 5.8836 - val_loss: 5.1780 - val_mae: 1.7518 - val_mse: 5.1780\n",
      "Epoch 36/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 5.1422 - mae: 1.7575 - mse: 5.1422 - val_loss: 4.1502 - val_mae: 1.5704 - val_mse: 4.1502\n",
      "Epoch 37/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 4.1830 - mae: 1.5861 - mse: 4.1830 - val_loss: 3.8090 - val_mae: 1.5067 - val_mse: 3.8090\n",
      "Epoch 38/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 3.9038 - mae: 1.5301 - mse: 3.9038 - val_loss: 4.2459 - val_mae: 1.5910 - val_mse: 4.2459\n",
      "Epoch 39/75\n",
      "2400/2400 [==============================] - 0s 155us/sample - loss: 4.3416 - mae: 1.6073 - mse: 4.3416 - val_loss: 4.5115 - val_mae: 1.6383 - val_mse: 4.5115\n",
      "Epoch 40/75\n",
      "2400/2400 [==============================] - 0s 158us/sample - loss: 4.5996 - mae: 1.6473 - mse: 4.5996 - val_loss: 4.0754 - val_mae: 1.5556 - val_mse: 4.0754\n",
      "Epoch 41/75\n",
      "2400/2400 [==============================] - 0s 159us/sample - loss: 4.1558 - mae: 1.5658 - mse: 4.1558 - val_loss: 3.5136 - val_mae: 1.4515 - val_mse: 3.5136\n",
      "Epoch 42/75\n",
      "2400/2400 [==============================] - 0s 159us/sample - loss: 3.5621 - mae: 1.4643 - mse: 3.5621 - val_loss: 3.4198 - val_mae: 1.4547 - val_mse: 3.4198\n",
      "Epoch 43/75\n",
      "2400/2400 [==============================] - 0s 161us/sample - loss: 3.3908 - mae: 1.4479 - mse: 3.3908 - val_loss: 3.6342 - val_mae: 1.5152 - val_mse: 3.6342\n",
      "Epoch 44/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 3.5170 - mae: 1.4907 - mse: 3.5170 - val_loss: 3.6996 - val_mae: 1.5360 - val_mse: 3.6996\n",
      "Epoch 45/75\n",
      "2400/2400 [==============================] - 0s 159us/sample - loss: 3.5525 - mae: 1.5056 - mse: 3.5525 - val_loss: 3.4445 - val_mae: 1.4836 - val_mse: 3.4445\n",
      "Epoch 46/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 3.3103 - mae: 1.4535 - mse: 3.3103 - val_loss: 3.0025 - val_mae: 1.3817 - val_mse: 3.0025\n",
      "Epoch 47/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 2.9102 - mae: 1.3577 - mse: 2.9102 - val_loss: 2.6611 - val_mae: 1.2896 - val_mse: 2.6611\n",
      "Epoch 48/75\n",
      "2400/2400 [==============================] - 0s 164us/sample - loss: 2.6151 - mae: 1.2767 - mse: 2.6151 - val_loss: 2.5770 - val_mae: 1.2544 - val_mse: 2.5770\n",
      "Epoch 49/75\n",
      "2400/2400 [==============================] - 0s 161us/sample - loss: 2.5598 - mae: 1.2529 - mse: 2.5598 - val_loss: 2.6090 - val_mae: 1.2541 - val_mse: 2.6090\n",
      "Epoch 50/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 2.6046 - mae: 1.2564 - mse: 2.6046 - val_loss: 2.5199 - val_mae: 1.2336 - val_mse: 2.5199\n",
      "Epoch 51/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 2.5085 - mae: 1.2332 - mse: 2.5085 - val_loss: 2.3053 - val_mae: 1.1875 - val_mse: 2.3053\n",
      "Epoch 52/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 2.2765 - mae: 1.1807 - mse: 2.2765 - val_loss: 2.1481 - val_mae: 1.1563 - val_mse: 2.1481\n",
      "Epoch 53/75\n",
      "2400/2400 [==============================] - 0s 160us/sample - loss: 2.1003 - mae: 1.1402 - mse: 2.1003 - val_loss: 2.1302 - val_mae: 1.1579 - val_mse: 2.1302\n",
      "Epoch 54/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 2.0704 - mae: 1.1367 - mse: 2.0704 - val_loss: 2.1680 - val_mae: 1.1706 - val_mse: 2.1680\n",
      "Epoch 55/75\n",
      "2400/2400 [==============================] - 0s 158us/sample - loss: 2.0952 - mae: 1.1452 - mse: 2.0952 - val_loss: 2.1318 - val_mae: 1.1608 - val_mse: 2.1318\n",
      "Epoch 56/75\n",
      "2400/2400 [==============================] - 0s 158us/sample - loss: 2.0577 - mae: 1.1348 - mse: 2.0577 - val_loss: 2.0190 - val_mae: 1.1281 - val_mse: 2.0190\n",
      "Epoch 57/75\n",
      "2400/2400 [==============================] - 0s 160us/sample - loss: 1.9535 - mae: 1.1033 - mse: 1.9535 - val_loss: 1.8982 - val_mae: 1.0909 - val_mse: 1.8982\n",
      "Epoch 58/75\n",
      "2400/2400 [==============================] - 0s 159us/sample - loss: 1.8478 - mae: 1.0708 - mse: 1.8478 - val_loss: 1.8304 - val_mae: 1.0669 - val_mse: 1.8304\n",
      "Epoch 59/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 1.7960 - mae: 1.0536 - mse: 1.7960 - val_loss: 1.8132 - val_mae: 1.0576 - val_mse: 1.8132\n",
      "Epoch 60/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 1.7910 - mae: 1.0504 - mse: 1.7910 - val_loss: 1.7902 - val_mae: 1.0500 - val_mse: 1.7902\n",
      "Epoch 61/75\n",
      "2400/2400 [==============================] - 0s 158us/sample - loss: 1.7725 - mae: 1.0453 - mse: 1.7725 - val_loss: 1.7277 - val_mae: 1.0337 - val_mse: 1.7277\n",
      "Epoch 62/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 1.7094 - mae: 1.0276 - mse: 1.7094 - val_loss: 1.6517 - val_mae: 1.0147 - val_mse: 1.6517\n",
      "Epoch 63/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 1.6335 - mae: 1.0066 - mse: 1.6335 - val_loss: 1.6061 - val_mae: 1.0036 - val_mse: 1.6061\n",
      "Epoch 64/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 1.5866 - mae: 0.9934 - mse: 1.5866 - val_loss: 1.5936 - val_mae: 1.0016 - val_mse: 1.5936\n",
      "Epoch 65/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 1.5718 - mae: 0.9897 - mse: 1.5718 - val_loss: 1.5765 - val_mae: 0.9984 - val_mse: 1.5765\n",
      "Epoch 66/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 1.5540 - mae: 0.9848 - mse: 1.5540 - val_loss: 1.5340 - val_mae: 0.9851 - val_mse: 1.5340\n",
      "Epoch 67/75\n",
      "2400/2400 [==============================] - 0s 158us/sample - loss: 1.5144 - mae: 0.9727 - mse: 1.5144 - val_loss: 1.4779 - val_mae: 0.9659 - val_mse: 1.4779\n",
      "Epoch 68/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 1.4636 - mae: 0.9565 - mse: 1.4636 - val_loss: 1.4316 - val_mae: 0.9494 - val_mse: 1.4316\n",
      "Epoch 69/75\n",
      "2400/2400 [==============================] - 0s 158us/sample - loss: 1.4233 - mae: 0.9432 - mse: 1.4233 - val_loss: 1.4034 - val_mae: 0.9388 - val_mse: 1.4034\n",
      "Epoch 70/75\n",
      "2400/2400 [==============================] - 0s 157us/sample - loss: 1.4002 - mae: 0.9353 - mse: 1.4002 - val_loss: 1.3838 - val_mae: 0.9319 - val_mse: 1.3838\n",
      "Epoch 71/75\n",
      "2400/2400 [==============================] - 0s 156us/sample - loss: 1.3849 - mae: 0.9309 - mse: 1.3849 - val_loss: 1.3641 - val_mae: 0.9260 - val_mse: 1.3641\n",
      "Epoch 72/75\n",
      "2400/2400 [==============================] - 0s 160us/sample - loss: 1.3671 - mae: 0.9258 - mse: 1.3671 - val_loss: 1.3410 - val_mae: 0.9193 - val_mse: 1.3410\n",
      "Epoch 73/75\n",
      "2400/2400 [==============================] - 0s 163us/sample - loss: 1.3416 - mae: 0.9176 - mse: 1.3416 - val_loss: 1.3198 - val_mae: 0.9134 - val_mse: 1.3198\n",
      "Epoch 74/75\n",
      "2400/2400 [==============================] - 0s 161us/sample - loss: 1.3145 - mae: 0.9087 - mse: 1.3145 - val_loss: 1.3044 - val_mae: 0.9091 - val_mse: 1.3044\n",
      "Epoch 75/75\n",
      "2400/2400 [==============================] - 0s 158us/sample - loss: 1.2933 - mae: 0.9016 - mse: 1.2933 - val_loss: 1.2975 - val_mae: 0.9085 - val_mse: 1.2975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fff6dd2a950>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    { 'biased_RPD': t_signal},\n",
    "    #{\"Q_avg\": t_inic_q_avg, \"Q_std\": box_size},\n",
    "    { \"Q_avg\": t_unit_vector},\n",
    "    \n",
    "    epochs= 75,\n",
    "    batch_size=10000,\n",
    "    validation_data = ({ 'biased_RPD': v_signal},\\\n",
    "                       {\"Q_avg\": v_unit_vector})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(f'./Output/Model/V1Fermi_Run4MC_photon_020222.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = model.predict({ 'biased_RPD': t_signal.astype(float)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit_vector(arr):\n",
    "    output = []\n",
    "    norm =  np.linalg.norm(arr, axis = 1)\n",
    "    for i in range(arr.shape[0]):\n",
    "        output.append([arr[i][0] / norm[i], arr[i][1] / norm[i]])\n",
    "    return np.array(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_ang(angA, angB):\n",
    "    output = []\n",
    "    for i in range(angA.shape[0]):\n",
    "        diff = angA[i] - angB[i]\n",
    "        if abs(diff) > np.pi:\n",
    "            min_diff = min(abs(diff + 2 * np.pi), abs(diff - 2 * np.pi))\n",
    "            diff = min_diff if diff < 0 else -min_diff\n",
    "        output.append(diff)\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "validA = np.load(f\"{path}/validA_dict.pickle\", allow_pickle=True)\n",
    "validB = np.load(f\"{path}/validB_dict.pickle\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_A = validA.to_numpy()\n",
    "np_B = validB.to_numpy()\n",
    "\n",
    "A_signal = process_signal(np_A[:, 8:])\n",
    "B_signal = process_signal(np_B[:, 8:])\n",
    "\n",
    "QA = model.predict([A_signal.astype(float)])\n",
    "QB = model.predict([B_signal.astype(float)])\n",
    "\n",
    "A_inic_q_avg = np_A[:, 2:4].astype(float)\n",
    "B_inic_q_avg = np_B[:, 2:4].astype(float)\n",
    "\n",
    "A_hit = np_A[:, 5]\n",
    "B_hit = np_B[:, 5]\n",
    "\n",
    "pt_nuclear = np_A[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dQA  = A_inic_q_avg.astype(float) - QA\n",
    "dQB  = B_inic_q_avg.astype(float)  - QB\n",
    "\n",
    "Adx = dQA[:,0]\n",
    "Ady = dQA[:,1]\n",
    "\n",
    "Bdx = dQB[:,0]\n",
    "Bdy = dQB[:,1]\n",
    "\n",
    "Apsi_rec = np.arctan2(QA[:,1],QA[:,0])\n",
    "Apsi_gen = np.arctan2(A_inic_q_avg[:,1],A_inic_q_avg[:,0])\n",
    "AR_rec = np.sqrt(QA[:,0] ** 2 + QA[:, 1] ** 2)\n",
    "\n",
    "\n",
    "Bpsi_rec = np.arctan2(QB[:,1],QB[:,0])\n",
    "Bpsi_gen = np.arctan2(B_inic_q_avg[:,1],B_inic_q_avg[:,0])\n",
    "BR_rec = np.sqrt(QB[:,0] ** 2 + QB[:, 1] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A_inic_q_avg = get_unit_vector(A_inic_q_avg)\n",
    "#B_inic_q_avg = get_unit_vector(B_inic_q_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vector(QA, QB):\n",
    "    NormA = np.linalg.norm(QA, axis = 1)\n",
    "    NormB = np.linalg.norm(QB, axis = 1)\n",
    "    NA = np.array([QA[:,0 ] / NormA, QA[:,1 ] / NormA])\n",
    "    NB = np.array([QB[:,0 ] / NormB, QB[:,1 ] / NormB])\n",
    "    flip_B = -NB\n",
    "    avgx = (NA[0] + flip_B[0]) / 2     \n",
    "    avgy = (NA[1] + flip_B[1]) / 2     \n",
    "    avg = np.arctan2(avgy, avgx)    \n",
    "    return NA, NB, avgx, avgy, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA, NB, avg_recon_x, avg_recon_y, avg_recon_angle = average_vector(QA, QB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_gen, NB_gen, avg_gen_x, avg_gen_y, avg_gen_angle = average_vector(A_inic_q_avg, B_inic_q_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Apsi_gen = np.arctan2(A_inic_q_avg[:,1],A_inic_q_avg[:,0])\n",
    "Apsi_true = validA.iloc[:,0].astype(float).to_numpy()\n",
    "\n",
    "\n",
    "Bpsi_gen = np.arctan2(B_inic_q_avg[:,1],B_inic_q_avg[:,0])\n",
    "Bpsi_true = validB.iloc[:,0].astype(float).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apsi_gen = np.arctan2(A_inic_q_avg[:,1],A_inic_q_avg[:,0])\n",
    "Apsi_true = np_A[:,2].astype(float)\n",
    "AX = np_A[:, 0].astype(float)\n",
    "AY = np_A[:, 1].astype(float)\n",
    "AR = np.sqrt(AX**2+AY**2)\n",
    "\n",
    "Bpsi_gen = np.arctan2(B_inic_q_avg[:,1],B_inic_q_avg[:,0])\n",
    "Bpsi_true = np_B[:,2].astype(float)\n",
    "BX = np_B[:, 0].astype(float)\n",
    "BY = np_B[:, 1].astype(float)\n",
    "BR = np.sqrt(BX**2+BY**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_rec = correct_ang(Apsi_gen, Apsi_rec) \n",
    "true_rec = correct_ang(Apsi_true, Apsi_rec) \n",
    "true_gen = correct_ang(Apsi_true, Apsi_gen) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "TreeA = {\"n_incident_neutron\": A_hit,\n",
    "        \"X_gen\":AX,\n",
    "         \"Y_gen\": AY,\n",
    "         \"R_gen\": AR,\n",
    "         \"Qx_rec\": QA[:,0],\n",
    "         \"Qy_rec\": QA[:,1],\n",
    "         \"dX\": Adx,\n",
    "         \"dY\": Ady,\n",
    "         \"psi_true\":Apsi_true,\n",
    "         \"psi_rec\":Apsi_rec,\n",
    "         \"psi_gen\": Apsi_gen,\n",
    "         \"R_rec\": AR_rec}\n",
    "\n",
    "TreeB = {\"n_incident_neutron\": B_hit,\n",
    "         \"X_gen\":BX,\n",
    "         \"Y_gen\": BY,\n",
    "         \"R_gen\": BR,\n",
    "         \"Qx_rec\": QB[:,0],\n",
    "         \"Qy_rec\": QB[:,1],\n",
    "         \"dX\": Bdx,\n",
    "         \"dY\": Bdy,\n",
    "         \"psi_true\":Bpsi_true,\n",
    "         \"psi_rec\":Bpsi_rec,\n",
    "         \"psi_gen\": Bpsi_gen,\n",
    "         \"R_rec\": BR_rec}\n",
    "\n",
    "Tree_arms = {\"NormAx\":NA[0],\n",
    "             \"NormAy\":NA[1],\n",
    "             \"NormBx\": -NB[0],\n",
    "             \"NormBy\": -NB[1],\n",
    "             \"Average_RP_vector_X\": avg_recon_x,\n",
    "             \"Average_RP_vector_Y\": avg_recon_y,\n",
    "             \"Average_RP_angle\": avg_recon_angle,\n",
    "             \"pt_nuclear\": pt_nuclear\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"./Output/fig/Performance/V1Fermi_Run4MC_qq_fiber_photon_020222/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(output_folder + \"TreeA.npy\", TreeA)\n",
    "np.save(output_folder + \"TreeB.npy\", TreeB)\n",
    "np.save(output_folder + \"Tree_arms.npy\", Tree_arms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wmlce-v1.7.0]",
   "language": "python",
   "name": "conda-env-wmlce-v1.7.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
